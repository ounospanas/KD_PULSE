{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ounospanas/KD_PULSE/blob/main/notebooks/KD_student_dalia_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "herbal-series",
      "metadata": {
        "id": "herbal-series"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "actual-relaxation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "actual-relaxation",
        "outputId": "8e920f40-190d-476e-b5d9-c1f0736c9f2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "scheduled-wrestling",
      "metadata": {
        "id": "scheduled-wrestling"
      },
      "outputs": [],
      "source": [
        "window = 8\n",
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s4gqpd8O5LAh",
        "outputId": "e26d6f8a-b430-4d9f-d800-6ade2b2dfb99"
      },
      "id": "s4gqpd8O5LAh",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "saved-scholar",
      "metadata": {
        "id": "saved-scholar"
      },
      "outputs": [],
      "source": [
        "# assumes that data have been stored to gdrive using the load_segment_data_.ipynb\n",
        "ppg_X = np.load('/content/drive/MyDrive/ppg_data/dalia_data.npy')\n",
        "y = np.load('/content/drive/MyDrive/ppg_data/dalia_y.npy')\n",
        "subs = np.load('/content/drive/MyDrive/ppg_data/dalia_subs.npy')\n",
        "acts = np.load('/content/drive/MyDrive/ppg_data/dalia_acts.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "discrete-jamaica",
      "metadata": {
        "id": "discrete-jamaica"
      },
      "outputs": [],
      "source": [
        "val_sets = [[5,6,7,8],[9,10,11,12],[13,14,15],[1,2,3,4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "english-green",
      "metadata": {
        "id": "english-green"
      },
      "outputs": [],
      "source": [
        "def defineSets(X, y, subs, v, t):\n",
        "    tests = []\n",
        "    vals = []\n",
        "\n",
        "    tests_b = []\n",
        "    vals_b = []\n",
        "\n",
        "    y_tests = []\n",
        "    y_vals = []\n",
        "\n",
        "    all_data = list(np.unique(subs))\n",
        "    [all_data.remove(i) for i in v]\n",
        "\n",
        "    ts= X[subs == t].reshape(-1,1,4,32*window)\n",
        "    val = X[np.in1d(subs, [i for i in v if i!=t])].reshape(-1,1,4,32*window)\n",
        "\n",
        "    y_ts= y[subs == t]\n",
        "    y_val = y[np.in1d(subs, [i for i in v if i!=t])]\n",
        "\n",
        "    tr = X[np.in1d(subs, all_data)].reshape(-1,1,4,32*window)\n",
        "    y_tr = y[np.in1d(subs, all_data)]\n",
        "\n",
        "    return tr, val, ts, y_tr, y_val, y_ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "finished-sunglasses",
      "metadata": {
        "id": "finished-sunglasses"
      },
      "outputs": [],
      "source": [
        "tr, vals, tests, y_tr, y_vals, y_tests = defineSets(ppg_X, y, subs, val_sets[0], val_sets[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "written-outreach",
      "metadata": {
        "id": "written-outreach"
      },
      "outputs": [],
      "source": [
        "def z_score(\n",
        "    train_s,\n",
        "    val_s,\n",
        "    test_s,\n",
        "):\n",
        "    train_signal = np.copy(train_s)\n",
        "    val_signal = np.copy(val_s)\n",
        "    test_signal = np.copy(test_s)\n",
        "\n",
        "    for i in range(train_signal.shape[2]):\n",
        "\n",
        "        mean = torch.mean(torch.from_numpy(train_signal[:, :, i, :]))\n",
        "        std = torch.std(torch.from_numpy(train_signal[:, :, i, :]))\n",
        "\n",
        "        print(mean,std)\n",
        "\n",
        "        train_signal[:, :, i, :] = (torch.from_numpy(train_signal[:, :, i, :]) - mean) / std\n",
        "        val_signal[:, :, i, :] = (torch.from_numpy(val_signal[:, :, i, :]) - mean) / std\n",
        "        test_signal[:, :, i, :] = (torch.from_numpy(test_signal[:, :, i, :]) - mean) / std\n",
        "\n",
        "    x_train = train_signal\n",
        "    x_val = val_signal\n",
        "    x_test = test_signal\n",
        "\n",
        "    return x_train, x_val, x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "severe-evaluation",
      "metadata": {
        "id": "severe-evaluation"
      },
      "outputs": [],
      "source": [
        "class ReadyData(Dataset):\n",
        "\n",
        "    def __init__(self, X, y, scale_X=False):\n",
        "        if not torch.is_tensor(X):\n",
        "            if scale_X:\n",
        "                for i in range(4):\n",
        "                    X[:,0,i,:] = StandardScaler().fit_transform(X[:,0,i,:]) #batch z-score\n",
        "            self.X = torch.Tensor(X)\n",
        "        if not torch.is_tensor(y):\n",
        "            self.y = torch.Tensor(y)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "capital-killing",
      "metadata": {
        "id": "capital-killing"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "sixth-liquid",
      "metadata": {
        "id": "sixth-liquid"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "composed-experiment",
      "metadata": {
        "id": "composed-experiment"
      },
      "outputs": [],
      "source": [
        "# exact same RConvPPG\n",
        "class Teacher(nn.Module):\n",
        "    def __init__(self, conv_blocks=3, conv_layers=3, in_channels=[1,32,48], out_channels=[32,48,64],\n",
        "             kernel_size=(1,5), dilation=2, padding=(0,4), dropout=[0.5,0.5,0.5], pooling_size=[(1,4),(1,2),(1,2)],\n",
        "              heads=4, dim=16, dense_out=32, ppg_channels=1):\n",
        "        super(Teacher, self).__init__()\n",
        "\n",
        "        # hyperparameters\n",
        "        self.conv_blocks = conv_blocks\n",
        "        self.conv_layers =conv_layers\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.padding = padding\n",
        "        self.dropout = dropout\n",
        "        self.pooling_size = pooling_size\n",
        "        self.heads = heads\n",
        "        self.dim = dim\n",
        "        self.dense_out = dense_out\n",
        "        self.ppg_channels = ppg_channels\n",
        "\n",
        "\n",
        "        self.conv11 = nn.Conv2d(in_channels=self.in_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv12 = nn.Conv2d(in_channels=self.out_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv13 = nn.Conv2d(in_channels=self.out_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(in_channels=self.in_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv22 = nn.Conv2d(in_channels=self.out_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv23 = nn.Conv2d(in_channels=self.out_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(in_channels=self.in_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv32 = nn.Conv2d(in_channels=self.out_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv33 = nn.Conv2d(in_channels=self.out_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "\n",
        "        self.multihead_attn = nn.MultiheadAttention(embed_dim=self.dim, num_heads=self.heads, batch_first=True, )\n",
        "        self.layer_norm = nn.LayerNorm(self.dim)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dense = nn.Linear(self.out_channels[2]*dim*self.ppg_channels,self.dense_out)\n",
        "        self.out = nn.Linear(self.dense_out,1)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(self.dropout[0])\n",
        "        self.dropout2 = nn.Dropout(self.dropout[1])\n",
        "        self.dropout3 = nn.Dropout(self.dropout[2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "\n",
        "        x1 = x[:,:,0:self.ppg_channels,:] #get PPG\n",
        "        x2 = x[:,:,self.ppg_channels:(self.ppg_channels+3),:] #get acc_x, acc_y, acc_z\n",
        "\n",
        "        attn_output, attn_output_weights = self.multihead_attn(\n",
        "            x1.reshape(-1,x1.shape[2]*x1.shape[1],x1.shape[3]), #query vector\n",
        "            x2.reshape(-1,x2.shape[2]*x2.shape[1],x2.shape[3]), #key vector\n",
        "            x2.reshape(-1,x2.shape[2]*x2.shape[1],x2.shape[3])) #value vector\n",
        "\n",
        "        attn_output = self.layer_norm(attn_output)\n",
        "\n",
        "        flat = self.flatten(attn_output)\n",
        "        out1 = self.dense(flat)\n",
        "        out2 = self.out(out1)\n",
        "\n",
        "        return out2, out1\n",
        "\n",
        "    def emb(self, x):\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = F.relu(self.conv12(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv13(x)), kernel_size=self.pooling_size[0], stride=self.pooling_size[0], ceil_mode=True)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv21(x))\n",
        "        x = F.relu(self.conv22(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv23(x)), kernel_size=self.pooling_size[1], stride=self.pooling_size[1], ceil_mode=True)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.conv31(x))\n",
        "        x = F.relu(self.conv32(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv33(x)), kernel_size=self.pooling_size[2], stride=self.pooling_size[2], ceil_mode=True)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "conventional-wisdom",
      "metadata": {
        "id": "conventional-wisdom"
      },
      "outputs": [],
      "source": [
        "class Student(nn.Module):\n",
        "    def __init__(self, conv_blocks=3, conv_layers=3, in_channels=[1,32,48], out_channels=[32,48,64],\n",
        "             kernel_size=(1,5), dilation=(1,2), padding=(0,4), dropout=[0.5,0.5,0.5], pooling_size=[(1,4),(1,2),(1,2)],\n",
        "              heads=4, dim=16, dense_out=32, ppg_channels=1):\n",
        "        super(Student, self).__init__()\n",
        "\n",
        "        # hyperparameters\n",
        "        self.conv_blocks = conv_blocks\n",
        "        self.conv_layers =conv_layers\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.padding = padding\n",
        "        self.dropout = dropout\n",
        "        self.pooling_size = pooling_size\n",
        "        self.heads = heads\n",
        "        self.dim = dim\n",
        "        self.dense_out = dense_out\n",
        "        self.ppg_channels = ppg_channels\n",
        "\n",
        "\n",
        "        self.conv11 = nn.Conv2d(in_channels=self.in_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv12 = nn.Conv2d(in_channels=self.out_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv13 = nn.Conv2d(in_channels=self.out_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(in_channels=self.in_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=(1,3), padding=(0,3))\n",
        "        self.conv22 = nn.Conv2d(in_channels=self.out_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=(1,3), padding=(0,3))\n",
        "        self.conv23 = nn.Conv2d(in_channels=self.out_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=(1,3), padding=(0,3))\n",
        "\n",
        "        self.conv31 = nn.Conv2d(in_channels=self.in_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=(1,4), padding=(0,4))\n",
        "        self.conv32 = nn.Conv2d(in_channels=self.out_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=(1,4), padding=(0,4))\n",
        "        self.conv33 = nn.Conv2d(in_channels=self.out_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=(1,4), padding=(0,4))\n",
        "\n",
        "        self.conv4 = nn.Conv2d(in_channels=self.out_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=(4,1), padding=(0,0))\n",
        "\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dense = nn.Linear(256,self.dense_out)\n",
        "        self.out = nn.Linear(self.dense_out,1)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(self.dropout[0])\n",
        "        self.dropout2 = nn.Dropout(self.dropout[1])\n",
        "        self.dropout3 = nn.Dropout(self.dropout[2])\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "        x = self.conv4(x)\n",
        "\n",
        "        flat = self.flatten(x)\n",
        "        out_1 = self.dense(flat)\n",
        "        out_2 = self.out(out_1)\n",
        "\n",
        "        return out_2, out_1\n",
        "\n",
        "    def emb(self, x):\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = F.relu(self.conv12(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv13(x)), kernel_size=self.pooling_size[0], stride=self.pooling_size[0], ceil_mode=True)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv21(x))\n",
        "        x = F.relu(self.conv22(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv23(x)), kernel_size=self.pooling_size[1], stride=self.pooling_size[1], ceil_mode=True)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.conv31(x))\n",
        "        x = F.relu(self.conv32(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv33(x)), kernel_size=self.pooling_size[2], stride=self.pooling_size[2], ceil_mode=True)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "republican-recommendation",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "republican-recommendation",
        "outputId": "acefd02d-3653-4016-caf2-513ab940f343"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "27241"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "device = torch.device(\"cuda\")\n",
        "\n",
        "model = Student(in_channels=[1,16,24], out_channels=[16,24,32], kernel_size=(1,3), dilation=(1,2),\n",
        "                         dropout=[0.1, 0.1, 0.1], padding=(0,2), pooling_size=[(1,4),(1,4),(1,2)])\n",
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "count_parameters(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "latest-keeping",
      "metadata": {
        "id": "latest-keeping"
      },
      "source": [
        "# Training loop with Knowldge Distillation (could be skipped and move to post-processing/evaluation section)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get paper's teacher models in case you didn't run training section in prvious notebook\n",
        "!git clone https://github.com/ounospanas/KD_PULSE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tXjZrZ5I5yIK",
        "outputId": "a391a472-4fc2-4094-9dc9-9cdb984f3e0b"
      },
      "id": "tXjZrZ5I5yIK",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KD_PULSE'...\n",
            "remote: Enumerating objects: 76, done.\u001b[K\n",
            "remote: Counting objects: 100% (76/76), done.\u001b[K\n",
            "remote: Compressing objects: 100% (71/71), done.\u001b[K\n",
            "remote: Total 76 (delta 15), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (76/76), 8.60 MiB | 19.10 MiB/s, done.\n",
            "Resolving deltas: 100% (15/15), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models_paper/"
      ],
      "metadata": {
        "id": "8lwNT8jb5psi"
      },
      "id": "8lwNT8jb5psi",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "diagnostic-madagascar",
      "metadata": {
        "scrolled": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "diagnostic-madagascar",
        "outputId": "203d64da-ec51-4b83-bc0b-515df4e35578"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjects val are [5, 6, 7, 8]\n",
            "Subject test is 5\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "(48721, 1, 4, 256)\n",
            "(11327, 1, 4, 256)\n",
            "(4649, 1, 4, 256)\n",
            "\n",
            "Train Epoch: 0 \tLoss: 23.275182, time: 4.581669\n",
            "Val set: Average loss: 15.6797\n",
            "New best loss: 15.679690466986763!!!!!!!!!!!!!!!!\n",
            "Test set: Average loss: 42.1259\n",
            "\n",
            "Train Epoch: 1 \tLoss: 11.470066, time: 4.436953\n",
            "Val set: Average loss: 14.2903\n",
            "New best loss: 14.29030736287435!!!!!!!!!!!!!!!!\n",
            "Test set: Average loss: 40.9488\n",
            "\n",
            "Train Epoch: 2 \tLoss: 10.925641, time: 4.670339\n",
            "Val set: Average loss: 13.3861\n",
            "New best loss: 13.386052841610379!!!!!!!!!!!!!!!!\n",
            "Test set: Average loss: 40.8744\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-4ea6740bda0d>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m                 \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss_fn_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m                 \u001b[0mcounter\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mtoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "val_maes = []\n",
        "test_maes = []\n",
        "scores = []\n",
        "\n",
        "for sub_vals in val_sets:\n",
        "\n",
        "    print('Subjects val are {}'.format(sub_vals))\n",
        "    for sub_tests in sub_vals:\n",
        "        print('Subject test is {}'.format(sub_tests))\n",
        "\n",
        "        tr, val, ts, _train_label, _val_label, _test_label = defineSets(ppg_X, y, subs, sub_vals, sub_tests)\n",
        "\n",
        "        X_train, X_val, X_test = z_score(tr, val, ts)\n",
        "\n",
        "        print(X_train.shape)\n",
        "        print(X_val.shape)\n",
        "        print(X_test.shape)\n",
        "\n",
        "        val_len = len(X_val)\n",
        "        train_len = len(X_train)\n",
        "        test_len = len(X_test)\n",
        "\n",
        "        ds_train = ReadyData(X=X_train, y=_train_label, scale_X=False)\n",
        "        ds_val = ReadyData(X=X_val, y=_val_label, scale_X=False)\n",
        "        ds_test = ReadyData(X=X_test, y=_test_label, scale_X=False)\n",
        "\n",
        "        batch_size = 256\n",
        "\n",
        "        train_set = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
        "        val_set = DataLoader(ds_val, batch_size=batch_size, shuffle=False)\n",
        "        test_set = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "\n",
        "        device = torch.device(\"cuda\")\n",
        "\n",
        "        teacher = Teacher()\n",
        "        teacher.load_state_dict(torch.load('KD_PULSE/PPG_Dalia_models/best_model_avg_all_acc_last_'+str(sub_tests)+'.pt'))\n",
        "\n",
        "        model = Student(in_channels=[1,16,24], out_channels=[16,24,32], kernel_size=(1,3), dilation=(1,2),\n",
        "                         dropout=[0.1, 0.1, 0.1], padding=(0,2), pooling_size=[(1,4),(1,4),(1,2)])\n",
        "\n",
        "        model.to(device)\n",
        "        teacher.to(device)\n",
        "\n",
        "        teacher.eval()\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-6)\n",
        "        loss_fn_1 = nn.L1Loss()\n",
        "        loss_fn_2 = nn.L1Loss()\n",
        "        loss_fn_3 = nn.MSELoss()\n",
        "\n",
        "        b = 0.5\n",
        "        g = 0.6667\n",
        "\n",
        "        best_loss = 100000000\n",
        "        best_epoch = 0\n",
        "\n",
        "        for epoch in range(500):\n",
        "            tic = time()\n",
        "\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            counter = 0\n",
        "\n",
        "\n",
        "            for batch_idx, (data, target) in enumerate(train_set):\n",
        "                data, target = Variable(data).float().to(device), Variable(target).float().to(device).reshape(-1,1)\n",
        "                distil = Variable(target).float().to(device)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                output, middle = model(data)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    teacher.eval()\n",
        "                    distil, out2 = teacher(data)\n",
        "\n",
        "                loss_1 = loss_fn_1(output, target)\n",
        "                loss_2 = loss_fn_2(output, distil.detach())\n",
        "\n",
        "                out2 = F.softmax(out2, dim=1)\n",
        "                middle = F.softmax(middle, dim=1)\n",
        "                loss_3 = loss_fn_3(out2.detach(), middle)\n",
        "\n",
        "                loss = g*(b*loss_1 + (1-b)*loss_2) + (1-g)*loss_3\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss_fn_1(output, target).item()\n",
        "                counter +=1\n",
        "            toc = time()\n",
        "\n",
        "            print('\\nTrain Epoch: {} \\tLoss: {:.6f}, time: {:.6f}'.format(epoch, train_loss/counter, toc-tic))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                val_loss = 0\n",
        "                counter = 0\n",
        "                custom_loss = 0\n",
        "\n",
        "                for data, target in val_set:\n",
        "                    data, target = Variable(data).float().to(device), Variable(target).float().to(device).reshape(-1,1)\n",
        "                    output,_ = model(data)\n",
        "\n",
        "                    # sum up batch loss\n",
        "                    val_loss += loss_fn_1(output, target).item()\n",
        "                    counter +=1\n",
        "\n",
        "                val_loss /= counter#len(test_set.dataset)\n",
        "\n",
        "                #custom_loss /= counter#len(test_set.dataset)\n",
        "                print('Val set: Average loss: {:.4f}'.format(val_loss))\n",
        "                if val_loss < best_loss:\n",
        "                    best_loss = val_loss\n",
        "                    print(\"New best loss: {}!!!!!!!!!!!!!!!!\".format(best_loss))\n",
        "                    torch.save(model.state_dict(), 'models_paper/best_model_distil_paper_'+str(sub_tests)+'.pt')\n",
        "                    best_epoch = epoch\n",
        "            if epoch>(best_epoch+100):\n",
        "                break\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                test_loss = 0\n",
        "                counter = 0\n",
        "                custom_loss = 0\n",
        "\n",
        "                for data, target in test_set:\n",
        "                    data, target = Variable(data).float().to(device), Variable(target).float().to(device).reshape(-1,1)\n",
        "                    output,_ = model(data)\n",
        "\n",
        "                    # sum up batch loss\n",
        "                    test_loss += loss_fn_1(output, target).item()\n",
        "                    counter +=1\n",
        "\n",
        "                test_loss /= counter#len(test_set.dataset)\n",
        "                print('Test set: Average loss: {:.4f}'.format(test_loss))\n",
        "\n",
        "\n",
        "        test_maes.append(test_loss)\n",
        "        val_maes.append(best_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "behavioral-planet",
      "metadata": {
        "id": "behavioral-planet"
      },
      "source": [
        "# Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment in case you didn't execute before\n",
        "# !git clone https://github.com/ounospanas/KD_PULSE.git"
      ],
      "metadata": {
        "id": "b-D8qFvH6eak"
      },
      "id": "b-D8qFvH6eak",
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "progressive-logan",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "progressive-logan",
        "outputId": "b7e10558-bb39-4036-d8e6-d32e7d136a94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjects val are [5, 6, 7, 8]\n",
            "Subjects val are 5\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "TEST MAE: 7.7606506\n",
            "Subjects val are 6\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "TEST MAE: 4.809272\n",
            "Subjects val are 7\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "TEST MAE: 2.49427\n",
            "Subjects val are 8\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "TEST MAE: 8.862795\n",
            "Subjects val are [9, 10, 11, 12]\n",
            "Subjects val are 9\n",
            "tensor(-6.4092e-05, dtype=torch.float64) tensor(79.1492, dtype=torch.float64)\n",
            "tensor(-0.5247, dtype=torch.float64) tensor(0.3407, dtype=torch.float64)\n",
            "tensor(0.1022, dtype=torch.float64) tensor(0.6423, dtype=torch.float64)\n",
            "tensor(0.3705, dtype=torch.float64) tensor(0.3983, dtype=torch.float64)\n",
            "TEST MAE: 8.636632\n",
            "Subjects val are 10\n",
            "tensor(-6.4092e-05, dtype=torch.float64) tensor(79.1492, dtype=torch.float64)\n",
            "tensor(-0.5247, dtype=torch.float64) tensor(0.3407, dtype=torch.float64)\n",
            "tensor(0.1022, dtype=torch.float64) tensor(0.6423, dtype=torch.float64)\n",
            "tensor(0.3705, dtype=torch.float64) tensor(0.3983, dtype=torch.float64)\n",
            "TEST MAE: 3.3994431\n",
            "Subjects val are 11\n",
            "tensor(-6.4092e-05, dtype=torch.float64) tensor(79.1492, dtype=torch.float64)\n",
            "tensor(-0.5247, dtype=torch.float64) tensor(0.3407, dtype=torch.float64)\n",
            "tensor(0.1022, dtype=torch.float64) tensor(0.6423, dtype=torch.float64)\n",
            "tensor(0.3705, dtype=torch.float64) tensor(0.3983, dtype=torch.float64)\n",
            "TEST MAE: 5.209723\n",
            "Subjects val are 12\n",
            "tensor(-6.4092e-05, dtype=torch.float64) tensor(79.1492, dtype=torch.float64)\n",
            "tensor(-0.5247, dtype=torch.float64) tensor(0.3407, dtype=torch.float64)\n",
            "tensor(0.1022, dtype=torch.float64) tensor(0.6423, dtype=torch.float64)\n",
            "tensor(0.3705, dtype=torch.float64) tensor(0.3983, dtype=torch.float64)\n",
            "TEST MAE: 7.5478935\n",
            "Subjects val are [13, 14, 15]\n",
            "Subjects val are 13\n",
            "tensor(0.0002, dtype=torch.float64) tensor(82.1464, dtype=torch.float64)\n",
            "tensor(-0.5093, dtype=torch.float64) tensor(0.3546, dtype=torch.float64)\n",
            "tensor(0.0804, dtype=torch.float64) tensor(0.6525, dtype=torch.float64)\n",
            "tensor(0.3688, dtype=torch.float64) tensor(0.4071, dtype=torch.float64)\n",
            "TEST MAE: 1.9326024\n",
            "Subjects val are 14\n",
            "tensor(0.0002, dtype=torch.float64) tensor(82.1464, dtype=torch.float64)\n",
            "tensor(-0.5093, dtype=torch.float64) tensor(0.3546, dtype=torch.float64)\n",
            "tensor(0.0804, dtype=torch.float64) tensor(0.6525, dtype=torch.float64)\n",
            "tensor(0.3688, dtype=torch.float64) tensor(0.4071, dtype=torch.float64)\n",
            "TEST MAE: 3.4551523\n",
            "Subjects val are 15\n",
            "tensor(0.0002, dtype=torch.float64) tensor(82.1464, dtype=torch.float64)\n",
            "tensor(-0.5093, dtype=torch.float64) tensor(0.3546, dtype=torch.float64)\n",
            "tensor(0.0804, dtype=torch.float64) tensor(0.6525, dtype=torch.float64)\n",
            "tensor(0.3688, dtype=torch.float64) tensor(0.4071, dtype=torch.float64)\n",
            "TEST MAE: 3.4421644\n",
            "Subjects val are [1, 2, 3, 4]\n",
            "Subjects val are 1\n",
            "tensor(-0.0002, dtype=torch.float64) tensor(88.6542, dtype=torch.float64)\n",
            "tensor(-0.5414, dtype=torch.float64) tensor(0.3586, dtype=torch.float64)\n",
            "tensor(0.0689, dtype=torch.float64) tensor(0.6485, dtype=torch.float64)\n",
            "tensor(0.3162, dtype=torch.float64) tensor(0.4033, dtype=torch.float64)\n",
            "TEST MAE: 4.3074765\n",
            "Subjects val are 2\n",
            "tensor(-0.0002, dtype=torch.float64) tensor(88.6542, dtype=torch.float64)\n",
            "tensor(-0.5414, dtype=torch.float64) tensor(0.3586, dtype=torch.float64)\n",
            "tensor(0.0689, dtype=torch.float64) tensor(0.6485, dtype=torch.float64)\n",
            "tensor(0.3162, dtype=torch.float64) tensor(0.4033, dtype=torch.float64)\n",
            "TEST MAE: 3.6506453\n",
            "Subjects val are 3\n",
            "tensor(-0.0002, dtype=torch.float64) tensor(88.6542, dtype=torch.float64)\n",
            "tensor(-0.5414, dtype=torch.float64) tensor(0.3586, dtype=torch.float64)\n",
            "tensor(0.0689, dtype=torch.float64) tensor(0.6485, dtype=torch.float64)\n",
            "tensor(0.3162, dtype=torch.float64) tensor(0.4033, dtype=torch.float64)\n",
            "TEST MAE: 2.3259215\n",
            "Subjects val are 4\n",
            "tensor(-0.0002, dtype=torch.float64) tensor(88.6542, dtype=torch.float64)\n",
            "tensor(-0.5414, dtype=torch.float64) tensor(0.3586, dtype=torch.float64)\n",
            "tensor(0.0689, dtype=torch.float64) tensor(0.6485, dtype=torch.float64)\n",
            "tensor(0.3162, dtype=torch.float64) tensor(0.4033, dtype=torch.float64)\n",
            "TEST MAE: 5.680264\n"
          ]
        }
      ],
      "source": [
        "val_maes = []\n",
        "scores = []\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "for sub_vals in val_sets:\n",
        "\n",
        "    print('Subjects val are {}'.format(sub_vals))\n",
        "    for sub_tests in sub_vals:\n",
        "        print('Subjects val are {}'.format(sub_tests))\n",
        "\n",
        "        tr, val, ts, _train_label, _val_label, _test_label = defineSets(ppg_X, y, subs, sub_vals, sub_tests)\n",
        "\n",
        "        X_train, X_val, X_test = z_score(tr, val, ts)\n",
        "\n",
        "        val_len = len(X_val)\n",
        "        train_len = len(X_train)\n",
        "        test_len = len(X_test)\n",
        "\n",
        "        ds_train = ReadyData(X=X_train, y=_train_label, scale_X=False)\n",
        "        ds_val = ReadyData(X=X_val, y=_val_label, scale_X=False)\n",
        "        ds_test = ReadyData(X=X_test, y=_test_label, scale_X=False)\n",
        "\n",
        "        batch_size = 256\n",
        "\n",
        "        train_set = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
        "        val_set = DataLoader(ds_val, batch_size=batch_size, shuffle=False)\n",
        "        test_set = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        device = torch.device(\"cuda\")\n",
        "\n",
        "        model = Student(in_channels=[1,16,24], out_channels=[16,24,32], kernel_size=(1,3), dilation=(1,2),\n",
        "                         dropout=[0.1, 0.1, 0.1], padding=(0,2), pooling_size=[(1,4),(1,4),(1,2)])\n",
        "        #comment if you ran the training part\n",
        "        model.load_state_dict(torch.load('KD_PULSE/distilled_paper_models/best_model_distil_paper_'+str(sub_tests)+'.pt'))\n",
        "        #uncomment if you ran the training part\n",
        "        #model.load_state_dict(torch.load('models_paper/best_model_distil_paper_'+str(sub_tests)+'.pt'))\n",
        "        model.to(device)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "        loss_fn = nn.L1Loss()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            correct_test = 0\n",
        "            test_loss = 0\n",
        "            counter = 0\n",
        "\n",
        "            preds_test,_ = model(Variable(torch.Tensor(X_test)).float().to(device))\n",
        "            preds_test = preds_test.cpu().detach().numpy()\n",
        "            targets_test = Variable(torch.Tensor(_test_label)).float().to(device).cpu().detach().numpy()\n",
        "            score_test = np.mean(np.abs(targets_test-preds_test))\n",
        "            print('TEST MAE:',score_test)\n",
        "\n",
        "\n",
        "\n",
        "        scores.append(score_test)\n",
        "        all_preds.append(preds_test)\n",
        "        all_targets.append(targets_test)\n",
        "        del X_train, _train_label, X_test, _test_label, X_val, _val_label\n",
        "        del tr, val, ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "constant-furniture",
      "metadata": {
        "id": "constant-furniture"
      },
      "outputs": [],
      "source": [
        "def post_processing(model, x_test, y_test, post=True):\n",
        "\n",
        "    post_MAE = []\n",
        "\n",
        "    preds = np.copy(x_test) #it should be model(x_test)\n",
        "\n",
        "    n = 10 #number_of_examples\n",
        "    thresh = 10\n",
        "\n",
        "\n",
        "    for i in range(n,len(preds)):\n",
        "        if post:\n",
        "            running_upper = np.mean(preds[(i-n):i])*(100+thresh)/100.0 #1.1\n",
        "            running_lower = np.mean(preds[(i-n):i])*(100-thresh)/100.0 #0.9\n",
        "\n",
        "            if preds[i] > running_upper:\n",
        "                preds[i] = running_upper\n",
        "                #print(preds[i])\n",
        "            if preds[i] < running_lower:\n",
        "                preds[i] = running_lower\n",
        "                #print(preds[i])\n",
        "\n",
        "    for j in range(len(preds)):\n",
        "        mae = np.abs(preds[j]-y_test[j])\n",
        "        post_MAE.append(mae)\n",
        "\n",
        "    return np.mean(post_MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "religious-latin",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "religious-latin",
        "outputId": "a0f5cb14-62c2-4775-8481-f8e73fe26746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.4944215\n"
          ]
        }
      ],
      "source": [
        "post_maes = []\n",
        "for i in range(15):\n",
        "    mae = post_processing(model, all_preds[i], all_targets[i])\n",
        "    post_maes.append(mae)\n",
        "print(np.mean(post_maes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "motivated-trade",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "motivated-trade",
        "outputId": "a37ecece-7cca-42db-c70b-d67f6649a65a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject 5 has MAE: 7.247197151184082\n",
            "Subject 6 has MAE: 4.36118221282959\n",
            "Subject 7 has MAE: 2.6458992958068848\n",
            "Subject 8 has MAE: 7.385950565338135\n",
            "Subject 9 has MAE: 8.093338012695312\n",
            "Subject 10 has MAE: 3.047382354736328\n",
            "Subject 11 has MAE: 5.015048027038574\n",
            "Subject 12 has MAE: 6.278552055358887\n",
            "Subject 13 has MAE: 2.1852259635925293\n",
            "Subject 14 has MAE: 3.1871988773345947\n",
            "Subject 15 has MAE: 3.369220495223999\n",
            "Subject 1 has MAE: 3.8374781608581543\n",
            "Subject 2 has MAE: 3.596951484680176\n",
            "Subject 3 has MAE: 2.306058406829834\n",
            "Subject 4 has MAE: 4.859644889831543\n"
          ]
        }
      ],
      "source": [
        "# print all scores for the subjects\n",
        "flattent_subjects = [item for row in val_sets for item in row]\n",
        "for i, sub in enumerate(flattent_subjects):\n",
        "  print(\"Subject {} has MAE: {}\".format(sub,post_maes[i]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NIWp0-AG7FYq"
      },
      "id": "NIWp0-AG7FYq",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py3.9",
      "language": "python",
      "name": "py3.9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}