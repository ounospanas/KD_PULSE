{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ounospanas/KD_PULSE/blob/main/notebooks/teacher_dalia_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "black-mapping",
      "metadata": {
        "id": "black-mapping"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.autograd import Variable\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "favorite-spouse",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "favorite-spouse",
        "outputId": "931a5f7d-0af3-4bd5-e821-639f2f7fd1bc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.1.0+cu121'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "torch.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "excess-velvet",
      "metadata": {
        "id": "excess-velvet"
      },
      "outputs": [],
      "source": [
        "window = 8\n",
        "batch_size = 256"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50K5NKTk0kh2",
        "outputId": "904ebcd1-55ee-44de-b3e5-7dddb597d92f"
      },
      "id": "50K5NKTk0kh2",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "forty-cancer",
      "metadata": {
        "id": "forty-cancer"
      },
      "outputs": [],
      "source": [
        "# assumes that data have been stored to gdrive using the load_segment_data_.ipynb\n",
        "ppg_X = np.load('/content/drive/MyDrive/ppg_data/dalia_data.npy')\n",
        "y = np.load('/content/drive/MyDrive/ppg_data/dalia_y.npy')\n",
        "subs = np.load('/content/drive/MyDrive/ppg_data/dalia_subs.npy')\n",
        "acts = np.load('/content/drive/MyDrive/ppg_data/dalia_acts.npy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "naval-natural",
      "metadata": {
        "id": "naval-natural"
      },
      "outputs": [],
      "source": [
        "val_sets = [[5,6,7,8],[9,10,11,12],[13,14,15],[1,2,3,4]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "crazy-syntax",
      "metadata": {
        "id": "crazy-syntax"
      },
      "outputs": [],
      "source": [
        "def defineSets(X, y, subs, v, t):\n",
        "    tests = []\n",
        "    vals = []\n",
        "\n",
        "    tests_b = []\n",
        "    vals_b = []\n",
        "\n",
        "    y_tests = []\n",
        "    y_vals = []\n",
        "\n",
        "    all_data = list(np.unique(subs))\n",
        "    [all_data.remove(i) for i in v]\n",
        "\n",
        "    ts= X[subs == t].reshape(-1,1,4,32*window)\n",
        "    val = X[np.in1d(subs, [i for i in v if i!=t])].reshape(-1,1,4,32*window)\n",
        "\n",
        "    y_ts= y[subs == t]\n",
        "    y_val = y[np.in1d(subs, [i for i in v if i!=t])]\n",
        "\n",
        "    tr = X[np.in1d(subs, all_data)].reshape(-1,1,4,32*window)\n",
        "    y_tr = y[np.in1d(subs, all_data)]\n",
        "\n",
        "    return tr, val, ts, y_tr, y_val, y_ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "noble-sleep",
      "metadata": {
        "id": "noble-sleep"
      },
      "outputs": [],
      "source": [
        "tr, vals, tests, y_tr, y_vals, y_tests = defineSets(ppg_X, y, subs, val_sets[0], val_sets[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "recent-productivity",
      "metadata": {
        "id": "recent-productivity"
      },
      "outputs": [],
      "source": [
        "def z_score(\n",
        "    train_s,\n",
        "    val_s,\n",
        "    test_s,\n",
        "):\n",
        "    train_signal = np.copy(train_s)\n",
        "    val_signal = np.copy(val_s)\n",
        "    test_signal = np.copy(test_s)\n",
        "\n",
        "    for i in range(train_signal.shape[2]):\n",
        "\n",
        "        mean = torch.mean(torch.from_numpy(train_signal[:, :, i, :]))\n",
        "        std = torch.std(torch.from_numpy(train_signal[:, :, i, :]))\n",
        "\n",
        "        print(mean,std)\n",
        "\n",
        "        train_signal[:, :, i, :] = (torch.from_numpy(train_signal[:, :, i, :]) - mean) / std\n",
        "        val_signal[:, :, i, :] = (torch.from_numpy(val_signal[:, :, i, :]) - mean) / std\n",
        "        test_signal[:, :, i, :] = (torch.from_numpy(test_signal[:, :, i, :]) - mean) / std\n",
        "\n",
        "    x_train = train_signal\n",
        "    x_val = val_signal\n",
        "    x_test = test_signal\n",
        "\n",
        "    return x_train, x_val, x_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "knowing-scope",
      "metadata": {
        "id": "knowing-scope"
      },
      "outputs": [],
      "source": [
        "class ReadyData(Dataset):\n",
        "\n",
        "    def __init__(self, X, y, scale_X=False):\n",
        "        if not torch.is_tensor(X):\n",
        "            if scale_X:\n",
        "                for i in range(4):\n",
        "                    X[:,0,i,:] = StandardScaler().fit_transform(X[:,0,i,:]) #batch z-score\n",
        "            self.X = torch.Tensor(X)\n",
        "        if not torch.is_tensor(y):\n",
        "            self.y = torch.Tensor(y)\n",
        "\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cellular-retention",
      "metadata": {
        "id": "cellular-retention"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "ancient-transmission",
      "metadata": {
        "id": "ancient-transmission"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import numpy as np\n",
        "from time import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "violent-dutch",
      "metadata": {
        "id": "violent-dutch"
      },
      "outputs": [],
      "source": [
        "class RConvPPG(nn.Module):\n",
        "    def __init__(self, conv_blocks=3, conv_layers=3, in_channels=[1,32,48], out_channels=[32,48,64],\n",
        "             kernel_size=(1,5), dilation=2, padding=(0,4), dropout=[0.5,0.5,0.5], pooling_size=[(1,4),(1,2),(1,2)],\n",
        "              heads=4, dim=16, dense_out=32, ppg_channels=1):\n",
        "        super(RConvPPG, self).__init__()\n",
        "\n",
        "        # hyperparameters\n",
        "        self.conv_blocks = conv_blocks\n",
        "        self.conv_layers =conv_layers\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.dilation = dilation\n",
        "        self.padding = padding\n",
        "        self.dropout = dropout\n",
        "        self.pooling_size = pooling_size\n",
        "        self.heads = heads\n",
        "        self.dim = dim\n",
        "        self.dense_out = dense_out\n",
        "        self.ppg_channels = ppg_channels\n",
        "\n",
        "\n",
        "        self.conv11 = nn.Conv2d(in_channels=self.in_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv12 = nn.Conv2d(in_channels=self.out_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv13 = nn.Conv2d(in_channels=self.out_channels[0], out_channels=self.out_channels[0],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "\n",
        "        self.conv21 = nn.Conv2d(in_channels=self.in_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv22 = nn.Conv2d(in_channels=self.out_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv23 = nn.Conv2d(in_channels=self.out_channels[1], out_channels=self.out_channels[1],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "\n",
        "        self.conv31 = nn.Conv2d(in_channels=self.in_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv32 = nn.Conv2d(in_channels=self.out_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "        self.conv33 = nn.Conv2d(in_channels=self.out_channels[2], out_channels=self.out_channels[2],\n",
        "                                kernel_size=self.kernel_size, dilation=self.dilation, padding=self.padding)\n",
        "\n",
        "        self.multihead_attn = nn.MultiheadAttention(embed_dim=self.dim, num_heads=self.heads, batch_first=True, )\n",
        "        self.layer_norm = nn.LayerNorm(self.dim)\n",
        "\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.dense = nn.Linear(self.out_channels[2]*dim*self.ppg_channels,self.dense_out)\n",
        "        self.out = nn.Linear(self.dense_out,1)\n",
        "\n",
        "        self.dropout1 = nn.Dropout(self.dropout[0])\n",
        "        self.dropout2 = nn.Dropout(self.dropout[1])\n",
        "        self.dropout3 = nn.Dropout(self.dropout[2])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.emb(x)\n",
        "\n",
        "        x1 = x[:,:,0:self.ppg_channels,:] #get PPG\n",
        "        x2 = x[:,:,self.ppg_channels:(self.ppg_channels+3),:] #get acc_x, acc_y, acc_z\n",
        "\n",
        "        attn_output, attn_output_weights = self.multihead_attn(\n",
        "            x1.reshape(-1,x1.shape[2]*x1.shape[1],x1.shape[3]), #query vector\n",
        "            x2.reshape(-1,x2.shape[2]*x2.shape[1],x2.shape[3]), #key vector\n",
        "            x2.reshape(-1,x2.shape[2]*x2.shape[1],x2.shape[3])) #value vector\n",
        "\n",
        "        attn_output = self.layer_norm(attn_output)\n",
        "\n",
        "        flat = self.flatten(attn_output)\n",
        "        out = self.dense(flat)\n",
        "        out = self.out(out)\n",
        "\n",
        "        return out, attn_output_weights\n",
        "\n",
        "    def emb(self, x):\n",
        "        x = F.relu(self.conv11(x))\n",
        "        x = F.relu(self.conv12(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv13(x)), kernel_size=self.pooling_size[0], stride=self.pooling_size[0], ceil_mode=True)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = F.relu(self.conv21(x))\n",
        "        x = F.relu(self.conv22(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv23(x)), kernel_size=self.pooling_size[1], stride=self.pooling_size[1], ceil_mode=True)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        x = F.relu(self.conv31(x))\n",
        "        x = F.relu(self.conv32(x))\n",
        "        x = F.avg_pool2d(F.relu(self.conv33(x)), kernel_size=self.pooling_size[2], stride=self.pooling_size[2], ceil_mode=True)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "composite-english",
      "metadata": {
        "id": "composite-english"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "premier-burden",
      "metadata": {
        "id": "premier-burden"
      },
      "source": [
        "# Training loop (could be skipped and go to the post-processing/evaluation section)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir models_paper"
      ],
      "metadata": {
        "id": "WS6l26282Fkl"
      },
      "id": "WS6l26282Fkl",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "stopped-investigator",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 749
        },
        "id": "stopped-investigator",
        "outputId": "3fa95549-09a5-49eb-ea1f-d82271a532e4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjects val are [5, 6, 7, 8]\n",
            "Subjects val are 5\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "(48721, 1, 4, 256)\n",
            "(11327, 1, 4, 256)\n",
            "(4649, 1, 4, 256)\n",
            "\n",
            "Train Epoch: 0 \tLoss: 21.6633, time: 7.5516\n",
            "TEST MAE: 31.349339\n",
            "Val set: Average loss: 17.4667\n",
            "New best loss: 17.46665488349067!!!!!!!!!!!!!!!!\n",
            "\n",
            "Train Epoch: 1 \tLoss: 9.4274, time: 7.6814\n",
            "TEST MAE: 28.630928\n",
            "Val set: Average loss: 13.6570\n",
            "New best loss: 13.65703042348226!!!!!!!!!!!!!!!!\n",
            "\n",
            "Train Epoch: 2 \tLoss: 8.3235, time: 7.6077\n",
            "TEST MAE: 21.882301\n",
            "Val set: Average loss: 10.9968\n",
            "New best loss: 10.996778313318888!!!!!!!!!!!!!!!!\n",
            "\n",
            "Train Epoch: 3 \tLoss: 7.5969, time: 7.6381\n",
            "TEST MAE: 18.228565\n",
            "Val set: Average loss: 11.5971\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-93e8955bca04>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#.reshape(-1,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "val_maes = []\n",
        "scores = []\n",
        "\n",
        "for sub_vals in val_sets:\n",
        "\n",
        "    print('Subjects val are {}'.format(sub_vals))\n",
        "    for sub_tests in sub_vals:\n",
        "        print('Subjects val are {}'.format(sub_tests))\n",
        "\n",
        "        tr, val, ts, _train_label, _val_label, _test_label = defineSets(ppg_X, y, subs, sub_vals, sub_tests)\n",
        "\n",
        "        X_train, X_val, X_test = z_score(tr, val, ts)\n",
        "\n",
        "        print(X_train.shape)\n",
        "        print(X_val.shape)\n",
        "        print(X_test.shape)\n",
        "\n",
        "        val_len = len(X_val)\n",
        "        train_len = len(X_train)\n",
        "        test_len = len(X_test)\n",
        "\n",
        "        ds_train = ReadyData(X=X_train, y=_train_label, scale_X=False)\n",
        "        ds_val = ReadyData(X=X_val, y=_val_label, scale_X=False)\n",
        "        ds_test = ReadyData(X=X_test, y=_test_label, scale_X=False)\n",
        "\n",
        "        batch_size = 256\n",
        "\n",
        "        train_set = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
        "        val_set = DataLoader(ds_val, batch_size=batch_size, shuffle=False)\n",
        "        test_set = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        device = torch.device(\"cuda\")\n",
        "\n",
        "        model = RConvPPG()\n",
        "        model.to(device)\n",
        "\n",
        "        optimizer = optim.Adam(model.parameters(), lr=0.0005) #0.0005 works also\n",
        "        loss_fn = nn.L1Loss()\n",
        "\n",
        "        best_loss = 100000000\n",
        "        best_epoch = 0\n",
        "\n",
        "        for epoch in range(500):\n",
        "            tic = time()\n",
        "\n",
        "            model.train()\n",
        "            train_loss = 0\n",
        "            counter = 0\n",
        "\n",
        "\n",
        "            for batch_idx, (data, target) in enumerate(train_set):\n",
        "\n",
        "                data, target = Variable(data).float().to(device), Variable(target).type(torch.FloatTensor).to(device)#.reshape(-1,1)\n",
        "\n",
        "                optimizer.zero_grad()\n",
        "                output,_ = model(data)\n",
        "                loss = loss_fn(output, target)\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                train_loss += loss.item()\n",
        "\n",
        "                counter +=1\n",
        "            toc = time()\n",
        "\n",
        "            print('\\nTrain Epoch: {} \\tLoss: {:.4f}, time: {:.4f}'.format(epoch, train_loss/counter,\n",
        "                                                                                              toc-tic))\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                correct_test = 0\n",
        "                test_loss = 0\n",
        "                counter = 0\n",
        "\n",
        "                preds_test,_ = model(Variable(torch.Tensor(X_test)).float().to(device))\n",
        "                preds_test = preds_test.cpu().detach().numpy()\n",
        "                targets_test = Variable(torch.Tensor(_test_label)).float().to(device).cpu().detach().numpy()\n",
        "                score_test = np.mean(np.abs(targets_test-preds_test))\n",
        "                print('TEST MAE:',score_test)\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "                model.eval()\n",
        "                correct_val = 0\n",
        "                val_loss = 0\n",
        "                counter = 0\n",
        "\n",
        "                for data, target in val_set:\n",
        "                    data, target = Variable(data).float().to(device), Variable(target).float().to(device)\n",
        "                    output,_ = model(data)\n",
        "\n",
        "                    # sum up batch loss\n",
        "                    val_loss += loss_fn(output, target).item()\n",
        "\n",
        "                    counter +=1\n",
        "\n",
        "                val_loss /= counter#len(test_set.dataset)\n",
        "\n",
        "                print('Val set: Average loss: {:.4f}'.format(val_loss))\n",
        "\n",
        "                if val_loss < best_loss:\n",
        "                    best_loss = val_loss\n",
        "                    print(\"New best loss: {}!!!!!!!!!!!!!!!!\".format(best_loss))\n",
        "                    torch.save(model.state_dict(), 'models_paper/best_model_avg_all_acc_last_'+str(sub_tests)+'.pt')\n",
        "                    best_epoch = epoch\n",
        "                    best_acc = correct_val/val_len\n",
        "                    best_score = score_test\n",
        "\n",
        "            if epoch>(best_epoch+150):\n",
        "                torch.save(model.state_dict(), 'models_paper/best_model_avg_all_acc_last_'+str(sub_tests)+'.pt')\n",
        "                break\n",
        "\n",
        "        val_maes.append(best_acc)\n",
        "        scores.append(best_score)\n",
        "        del X_train, _train_label, X_test, _test_label, X_val, _val_label\n",
        "        del tr, val, ts"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "arbitrary-trick",
      "metadata": {
        "id": "arbitrary-trick"
      },
      "source": [
        "# Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get paper's models in case you didn't run training section\n",
        "!git clone https://github.com/ounospanas/KD_PULSE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTreuH8S2aXY",
        "outputId": "7e184a60-3341-463d-977e-7982e98557b3"
      },
      "id": "XTreuH8S2aXY",
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'KD_PULSE'...\n",
            "remote: Enumerating objects: 72, done.\u001b[K\n",
            "remote: Counting objects: 100% (72/72), done.\u001b[K\n",
            "remote: Compressing objects: 100% (67/67), done.\u001b[K\n",
            "remote: Total 72 (delta 13), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (72/72), 8.59 MiB | 15.12 MiB/s, done.\n",
            "Resolving deltas: 100% (13/13), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "common-bidder",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "common-bidder",
        "outputId": "73307389-02e9-445f-f036-2a084c4567c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subjects val are [5, 6, 7, 8]\n",
            "Subjects val are 5\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "TEST MAE: 7.4337406\n",
            "Subjects val are 6\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "TEST MAE: 4.21625\n",
            "Subjects val are 7\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "TEST MAE: 2.2773478\n",
            "Subjects val are 8\n",
            "tensor(-0.0005, dtype=torch.float64) tensor(85.9549, dtype=torch.float64)\n",
            "tensor(-0.5196, dtype=torch.float64) tensor(0.3501, dtype=torch.float64)\n",
            "tensor(0.1493, dtype=torch.float64) tensor(0.6334, dtype=torch.float64)\n",
            "tensor(0.3673, dtype=torch.float64) tensor(0.4099, dtype=torch.float64)\n",
            "TEST MAE: 8.92644\n",
            "Subjects val are [9, 10, 11, 12]\n",
            "Subjects val are 9\n",
            "tensor(-6.4092e-05, dtype=torch.float64) tensor(79.1492, dtype=torch.float64)\n",
            "tensor(-0.5247, dtype=torch.float64) tensor(0.3407, dtype=torch.float64)\n",
            "tensor(0.1022, dtype=torch.float64) tensor(0.6423, dtype=torch.float64)\n",
            "tensor(0.3705, dtype=torch.float64) tensor(0.3983, dtype=torch.float64)\n",
            "TEST MAE: 6.9543953\n",
            "Subjects val are 10\n",
            "tensor(-6.4092e-05, dtype=torch.float64) tensor(79.1492, dtype=torch.float64)\n",
            "tensor(-0.5247, dtype=torch.float64) tensor(0.3407, dtype=torch.float64)\n",
            "tensor(0.1022, dtype=torch.float64) tensor(0.6423, dtype=torch.float64)\n",
            "tensor(0.3705, dtype=torch.float64) tensor(0.3983, dtype=torch.float64)\n",
            "TEST MAE: 2.9338408\n",
            "Subjects val are 11\n",
            "tensor(-6.4092e-05, dtype=torch.float64) tensor(79.1492, dtype=torch.float64)\n",
            "tensor(-0.5247, dtype=torch.float64) tensor(0.3407, dtype=torch.float64)\n",
            "tensor(0.1022, dtype=torch.float64) tensor(0.6423, dtype=torch.float64)\n",
            "tensor(0.3705, dtype=torch.float64) tensor(0.3983, dtype=torch.float64)\n",
            "TEST MAE: 3.9776318\n",
            "Subjects val are 12\n",
            "tensor(-6.4092e-05, dtype=torch.float64) tensor(79.1492, dtype=torch.float64)\n",
            "tensor(-0.5247, dtype=torch.float64) tensor(0.3407, dtype=torch.float64)\n",
            "tensor(0.1022, dtype=torch.float64) tensor(0.6423, dtype=torch.float64)\n",
            "tensor(0.3705, dtype=torch.float64) tensor(0.3983, dtype=torch.float64)\n",
            "TEST MAE: 6.568249\n",
            "Subjects val are [13, 14, 15]\n",
            "Subjects val are 13\n",
            "tensor(0.0002, dtype=torch.float64) tensor(82.1464, dtype=torch.float64)\n",
            "tensor(-0.5093, dtype=torch.float64) tensor(0.3546, dtype=torch.float64)\n",
            "tensor(0.0804, dtype=torch.float64) tensor(0.6525, dtype=torch.float64)\n",
            "tensor(0.3688, dtype=torch.float64) tensor(0.4071, dtype=torch.float64)\n",
            "TEST MAE: 1.7008717\n",
            "Subjects val are 14\n",
            "tensor(0.0002, dtype=torch.float64) tensor(82.1464, dtype=torch.float64)\n",
            "tensor(-0.5093, dtype=torch.float64) tensor(0.3546, dtype=torch.float64)\n",
            "tensor(0.0804, dtype=torch.float64) tensor(0.6525, dtype=torch.float64)\n",
            "tensor(0.3688, dtype=torch.float64) tensor(0.4071, dtype=torch.float64)\n",
            "TEST MAE: 3.2202213\n",
            "Subjects val are 15\n",
            "tensor(0.0002, dtype=torch.float64) tensor(82.1464, dtype=torch.float64)\n",
            "tensor(-0.5093, dtype=torch.float64) tensor(0.3546, dtype=torch.float64)\n",
            "tensor(0.0804, dtype=torch.float64) tensor(0.6525, dtype=torch.float64)\n",
            "tensor(0.3688, dtype=torch.float64) tensor(0.4071, dtype=torch.float64)\n",
            "TEST MAE: 2.8814\n",
            "Subjects val are [1, 2, 3, 4]\n",
            "Subjects val are 1\n",
            "tensor(-0.0002, dtype=torch.float64) tensor(88.6542, dtype=torch.float64)\n",
            "tensor(-0.5414, dtype=torch.float64) tensor(0.3586, dtype=torch.float64)\n",
            "tensor(0.0689, dtype=torch.float64) tensor(0.6485, dtype=torch.float64)\n",
            "tensor(0.3162, dtype=torch.float64) tensor(0.4033, dtype=torch.float64)\n",
            "TEST MAE: 4.748976\n",
            "Subjects val are 2\n",
            "tensor(-0.0002, dtype=torch.float64) tensor(88.6542, dtype=torch.float64)\n",
            "tensor(-0.5414, dtype=torch.float64) tensor(0.3586, dtype=torch.float64)\n",
            "tensor(0.0689, dtype=torch.float64) tensor(0.6485, dtype=torch.float64)\n",
            "tensor(0.3162, dtype=torch.float64) tensor(0.4033, dtype=torch.float64)\n",
            "TEST MAE: 3.313453\n",
            "Subjects val are 3\n",
            "tensor(-0.0002, dtype=torch.float64) tensor(88.6542, dtype=torch.float64)\n",
            "tensor(-0.5414, dtype=torch.float64) tensor(0.3586, dtype=torch.float64)\n",
            "tensor(0.0689, dtype=torch.float64) tensor(0.6485, dtype=torch.float64)\n",
            "tensor(0.3162, dtype=torch.float64) tensor(0.4033, dtype=torch.float64)\n",
            "TEST MAE: 2.223684\n",
            "Subjects val are 4\n",
            "tensor(-0.0002, dtype=torch.float64) tensor(88.6542, dtype=torch.float64)\n",
            "tensor(-0.5414, dtype=torch.float64) tensor(0.3586, dtype=torch.float64)\n",
            "tensor(0.0689, dtype=torch.float64) tensor(0.6485, dtype=torch.float64)\n",
            "tensor(0.3162, dtype=torch.float64) tensor(0.4033, dtype=torch.float64)\n",
            "TEST MAE: 5.2543283\n"
          ]
        }
      ],
      "source": [
        "val_maes = []\n",
        "scores = []\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "for sub_vals in val_sets:\n",
        "\n",
        "    print('Subjects val are {}'.format(sub_vals))\n",
        "    for sub_tests in sub_vals:\n",
        "        print('Subjects val are {}'.format(sub_tests))\n",
        "\n",
        "        tr, val, ts, _train_label, _val_label, _test_label = defineSets(ppg_X, y, subs, sub_vals, sub_tests)\n",
        "\n",
        "        X_train, X_val, X_test = z_score(tr, val, ts)\n",
        "\n",
        "        val_len = len(X_val)\n",
        "        train_len = len(X_train)\n",
        "        test_len = len(X_test)\n",
        "\n",
        "        ds_train = ReadyData(X=X_train, y=_train_label, scale_X=False)\n",
        "        ds_val = ReadyData(X=X_val, y=_val_label, scale_X=False)\n",
        "        ds_test = ReadyData(X=X_test, y=_test_label, scale_X=False)\n",
        "\n",
        "        batch_size = 256\n",
        "\n",
        "        train_set = DataLoader(ds_train, batch_size=batch_size, shuffle=True)\n",
        "        val_set = DataLoader(ds_val, batch_size=batch_size, shuffle=False)\n",
        "        test_set = DataLoader(ds_test, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "        device = torch.device(\"cuda\")\n",
        "\n",
        "        model = RConvPPG()\n",
        "        #comment if you ran the training part\n",
        "        model.load_state_dict(torch.load('KD_PULSE/PPG_Dalia_models/best_model_avg_all_acc_last_'+str(sub_tests)+'.pt'))\n",
        "        #uncomment if you ran the training part\n",
        "        #model.load_state_dict(torch.load('models_paper/best_model_avg_all_acc_last_'+str(sub_tests)+'.pt'))\n",
        "        model.to(device)\n",
        "\n",
        "        loss_fn = nn.L1Loss()\n",
        "\n",
        "        with torch.no_grad():\n",
        "            model.eval()\n",
        "            correct_test = 0\n",
        "            test_loss = 0\n",
        "            counter = 0\n",
        "\n",
        "            preds_test,_ = model(Variable(torch.Tensor(X_test)).float().to(device))\n",
        "            preds_test = preds_test.cpu().detach().numpy()\n",
        "            targets_test = Variable(torch.Tensor(_test_label)).float().to(device).cpu().detach().numpy()\n",
        "            score_test = np.mean(np.abs(targets_test-preds_test))\n",
        "            print('TEST MAE:',score_test)\n",
        "\n",
        "\n",
        "\n",
        "        scores.append(score_test)\n",
        "        all_preds.append(preds_test)\n",
        "        all_targets.append(targets_test)\n",
        "        del X_train, _train_label, X_test, _test_label, X_val, _val_label\n",
        "        del tr, val, ts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "daily-bibliography",
      "metadata": {
        "id": "daily-bibliography"
      },
      "outputs": [],
      "source": [
        "def post_processing(model, x_test, y_test, post=True):\n",
        "\n",
        "    post_MAE = []\n",
        "\n",
        "    preds = np.copy(x_test) #it should be model(x_test)\n",
        "\n",
        "    n = 10 #number_of_examples\n",
        "    thresh = 10\n",
        "\n",
        "\n",
        "    for i in range(n,len(preds)):\n",
        "        if post:\n",
        "            running_upper = np.mean(preds[(i-n):i])*(100+thresh)/100.0 #1.1\n",
        "            running_lower = np.mean(preds[(i-n):i])*(100-thresh)/100.0 #0.9\n",
        "\n",
        "            if preds[i] > running_upper:\n",
        "                preds[i] = running_upper\n",
        "                #print(preds[i])\n",
        "            if preds[i] < running_lower:\n",
        "                preds[i] = running_lower\n",
        "                #print(preds[i])\n",
        "\n",
        "    for j in range(len(preds)):\n",
        "        mae = np.abs(preds[j]-y_test[j])\n",
        "        post_MAE.append(mae)\n",
        "\n",
        "    return np.mean(post_MAE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "treated-facial",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "treated-facial",
        "outputId": "322d6f4b-3ec3-4628-db08-dff2528b98b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0269256\n"
          ]
        }
      ],
      "source": [
        "post_maes = []\n",
        "for i in range(15):\n",
        "    mae = post_processing(model, all_preds[i], all_targets[i])\n",
        "    post_maes.append(mae)\n",
        "print(np.mean(post_maes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "mediterranean-detector",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mediterranean-detector",
        "outputId": "91a249eb-b778-4ee5-d15b-9191948c0337"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Subject 5 has MAE: 6.947514057159424\n",
            "Subject 6 has MAE: 3.7082343101501465\n",
            "Subject 7 has MAE: 2.3935508728027344\n",
            "Subject 8 has MAE: 8.170137405395508\n",
            "Subject 9 has MAE: 6.192663192749023\n",
            "Subject 10 has MAE: 2.596329689025879\n",
            "Subject 11 has MAE: 3.8525259494781494\n",
            "Subject 12 has MAE: 5.219122409820557\n",
            "Subject 13 has MAE: 1.9768399000167847\n",
            "Subject 14 has MAE: 3.1287477016448975\n",
            "Subject 15 has MAE: 2.793991804122925\n",
            "Subject 1 has MAE: 3.7777018547058105\n",
            "Subject 2 has MAE: 3.037588596343994\n",
            "Subject 3 has MAE: 2.201739549636841\n",
            "Subject 4 has MAE: 4.407191753387451\n"
          ]
        }
      ],
      "source": [
        "# print all scores for the subjects\n",
        "flattent_subjects = [item for row in val_sets for item in row]\n",
        "for i, sub in enumerate(flattent_subjects):\n",
        "  print(\"Subject {} has MAE: {}\".format(sub,post_maes[i]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "reverse-prophet",
      "metadata": {
        "id": "reverse-prophet"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "py3.9",
      "language": "python",
      "name": "py3.9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}